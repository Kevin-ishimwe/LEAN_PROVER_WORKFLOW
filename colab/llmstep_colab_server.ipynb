{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wellecks/llmstep/blob/master/python/colab/llmstep_colab_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXc849NMr4Ks"
      },
      "source": [
        "# [`llmstep`](https://github.com/wellecks/llmstep) server using Colab notebook\n",
        "In order to use this notebook, follow these instructions:\n",
        "\n",
        "0. First, enable GPU by going to `Runtime` -> `Change runtime type` -> `T4 GPU`.\n",
        "\n",
        "1. Run all the cells in this colab notebook to start your server.\n",
        "\n",
        "2. In your local environment, set the environment variable `LLMSTEP_HOST` equal to the url printed out in this notebook (for example, https://04fa-34-125-110-83.ngrok.io/)\n",
        "\n",
        "3. In your local environment, set the environment variable `LLMSTEP_SERVER=COLAB`.\n",
        "\n",
        "4. Use `llmstep`.\n",
        "\n",
        "\n",
        "#### VSCode steps (2) and (3)\n",
        "\n",
        "To set environment variables in VS Code, go to:\n",
        "\n",
        "- Settings (`Command` + `,` on Mac)\n",
        "- Extensions -> Lean 4\n",
        "- Add environment variables to `Server Env`.\n",
        "- Then restart the Lean Server (`Command` + `t`, then type `> Lean 4: Restart Server`)\n",
        "\n",
        "\n",
        "Authors: Rahul Saha, Sean Welleck"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup `llmstep` code"
      ],
      "metadata": {
        "id": "F1zKZXLrArH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install flask\n",
        "!pip install transformers\n",
        "!pip install flask_ngrok\n",
        "\n",
        "!wget https://github.com/wellecks/llmstep/archive/92990596f91aad7e1323a8985d46a488ce8aef57.zip\n",
        "!unzip 92990596f91aad7e1323a8985d46a488ce8aef57.zip\n",
        "\n",
        "import sys\n",
        "sys.path.append('./llmstep-92990596f91aad7e1323a8985d46a488ce8aef57/python/')\n",
        "\n",
        "import server"
      ],
      "metadata": {
        "id": "S2IJ1_KcAvz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-WRNlphi1A_"
      },
      "source": [
        "### Run : load the model and start the server\n",
        "\n",
        "The cell prints out the public URL, for instance: https://04fa-34-125-110-73.ngrok.io\n",
        "\n",
        "**Add this URL as a `LLMSTEP_HOST` environment variable in your local environment.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M52N1j8i0Cg"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a tunnel\n",
        "port = 80\n",
        "public_url = ngrok.connect(port)\n",
        "\n",
        "# Setup the config (modify the options here if you want)\n",
        "config = {\n",
        "    'LLMSTEP_MODEL': 'wellecks/llmstep-mathlib4-pythia2.8b',\n",
        "    'LLMSTEP_TEMPERATURES': [0.5],\n",
        "    'LLMSTEP_NUM_SAMPLES': 5,\n",
        "    'LLMSTEP_PROMPT': server.llmstep_prompt,\n",
        "    'LLMSTEP_HOST': '',\n",
        "    'LLMSTEP_PORT': port\n",
        "}\n",
        "\n",
        "# Load the model\n",
        "print(\"Loading model...\")\n",
        "model, tokenizer = server.load_hf(config['LLMSTEP_MODEL'])\n",
        "print(\"Loading model done.\")\n",
        "\n",
        "# Start the server\n",
        "httpd = server.LLMStepServer(\n",
        "    model, tokenizer, server.hf_generate, config\n",
        ")\n",
        "\n",
        "print('Your public url is:\\n%s\\n\\nSet LLMSTEP_HOST to this url.' % public_url.public_url)\n",
        "print('Server started')\n",
        "httpd.serve_forever()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "i0HSL0v9TegT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}